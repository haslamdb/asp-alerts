{% extends "base.html" %}

{% block title %}LLM Performance - ASP/IP Metrics - {{ app_name }}{% endblock %}

{% block content %}
<div class="page-header">
    <h1>LLM Extraction Performance</h1>
    <p class="page-description">Cross-module analysis of LLM extraction accuracy, override patterns, and confidence calibration.</p>
</div>

{% if error is defined and error %}
<div class="alert alert-error">
    <strong>Error loading LLM performance:</strong> {{ error }}
</div>
{% endif %}

{# Filter bar #}
<form method="get" class="llm-filter-bar">
    <div class="llm-filter-group">
        <label for="filter-days">Period:</label>
        <select id="filter-days" name="days" onchange="this.form.submit()">
            {% for d in [7, 14, 30, 60, 90] %}
            <option value="{{ d }}" {% if current_days == d %}selected{% endif %}>Last {{ d }} days</option>
            {% endfor %}
        </select>
    </div>
    <div class="llm-filter-group">
        <label for="filter-module">Module:</label>
        <select id="filter-module" name="module" onchange="this.form.submit()">
            <option value="">All Modules</option>
            {% for mod in ["abx_indications", "guideline_adherence", "hai_detection", "drug_bug_mismatch", "surgical_prophylaxis"] %}
            <option value="{{ mod }}" {% if current_module == mod %}selected{% endif %}>{{ mod | replace("_", " ") | title }}</option>
            {% endfor %}
        </select>
    </div>
    <div class="llm-filter-group">
        <a href="{{ url_for('asp_metrics.dashboard') }}" class="btn btn-secondary">Back to Metrics</a>
    </div>
</form>

{# Summary stats cards #}
<div class="stats-grid">
    <div class="stat-card">
        <div class="stat-value">{{ stats.get('total_reviewed', 0) }}</div>
        <div class="stat-label">Total Reviewed</div>
        <div class="stat-sublabel">{{ current_days }} day period</div>
    </div>
    <div class="stat-card {% if stats.get('acceptance_rate') is not none and stats.acceptance_rate >= 80 %}stat-good{% endif %}">
        <div class="stat-value">
            {% if stats.get('acceptance_rate') is not none %}
                {{ stats.acceptance_rate }}%
            {% else %}
                --
            {% endif %}
        </div>
        <div class="stat-label">Acceptance Rate</div>
        <div class="stat-sublabel">{{ stats.get('accepted', 0) }} accepted, {{ stats.get('modified', 0) }} modified</div>
    </div>
    <div class="stat-card {% if stats.get('override_rate') is not none and stats.override_rate > 20 %}stat-warning{% endif %}">
        <div class="stat-value">
            {% if stats.get('override_rate') is not none %}
                {{ stats.override_rate }}%
            {% else %}
                --
            {% endif %}
        </div>
        <div class="stat-label">Override Rate</div>
        <div class="stat-sublabel">{{ stats.get('overridden', 0) }} overridden</div>
    </div>
    <div class="stat-card">
        <div class="stat-value">
            {% if stats.get('avg_confidence_accepted') %}
                {{ "%.1f"|format(stats.avg_confidence_accepted * 100) }}%
            {% else %}
                --
            {% endif %}
        </div>
        <div class="stat-label">Avg Confidence (Accepted)</div>
        <div class="stat-sublabel">vs {% if stats.get('avg_confidence_overridden') %}{{ "%.1f"|format(stats.avg_confidence_overridden * 100) }}%{% else %}--{% endif %} (Overridden)</div>
    </div>
</div>

{# Outcome Breakdown #}
{% if stats.get('total_reviewed', 0) > 0 %}
<div class="dashboard-card">
    <h3>Decision Outcome Breakdown</h3>
    <div class="outcome-summary">
        <div class="outcome-item outcome-accepted">
            <span class="outcome-count">{{ stats.get('accepted', 0) }}</span>
            <span class="outcome-label">Accepted</span>
        </div>
        <div class="outcome-item outcome-modified">
            <span class="outcome-count">{{ stats.get('modified', 0) }}</span>
            <span class="outcome-label">Modified</span>
        </div>
        <div class="outcome-item outcome-overridden">
            <span class="outcome-count">{{ stats.get('overridden', 0) }}</span>
            <span class="outcome-label">Overridden</span>
        </div>
    </div>
</div>
{% endif %}

{# Module comparison table #}
<div class="dashboard-card">
    <h3>Performance by Module</h3>
    {% if module_comparison %}
    <table class="data-table">
        <thead>
            <tr>
                <th>Module</th>
                <th>Total</th>
                <th>Accepted</th>
                <th>Overridden</th>
                <th>Acceptance Rate</th>
                <th>Avg Confidence</th>
                <th>Avg Review Time</th>
            </tr>
        </thead>
        <tbody>
            {% for mod in module_comparison %}
            <tr>
                <td><strong>{{ mod.module | replace('_', ' ') | title }}</strong></td>
                <td>{{ mod.total }}</td>
                <td>{{ mod.accepted }}</td>
                <td>{{ mod.overridden }}</td>
                <td>
                    {% if mod.acceptance_rate is not none %}
                        <span class="rate-badge {% if mod.acceptance_rate >= 80 %}rate-good{% elif mod.acceptance_rate >= 60 %}rate-ok{% else %}rate-low{% endif %}">
                            {{ mod.acceptance_rate }}%
                        </span>
                    {% else %}
                        --
                    {% endif %}
                </td>
                <td>
                    {% if mod.avg_confidence %}
                        {{ "%.1f"|format(mod.avg_confidence * 100) }}%
                    {% else %}
                        --
                    {% endif %}
                </td>
                <td>
                    {% if mod.avg_review_seconds %}
                        {% if mod.avg_review_seconds >= 60 %}
                            {{ "%.1f"|format(mod.avg_review_seconds / 60) }} min
                        {% else %}
                            {{ "%.0f"|format(mod.avg_review_seconds) }}s
                        {% endif %}
                    {% else %}
                        --
                    {% endif %}
                </td>
            </tr>
            {% endfor %}
        </tbody>
    </table>
    {% else %}
    <p class="empty-state">No LLM decision data available for this period</p>
    {% endif %}
</div>

{# Override reasons breakdown #}
{% if stats.get('override_reasons') %}
<div class="dashboard-card">
    <h3>Override Reasons</h3>
    <table class="data-table">
        <thead>
            <tr>
                <th>Reason</th>
                <th>Count</th>
                <th>% of Overrides</th>
                <th>Visual</th>
            </tr>
        </thead>
        <tbody>
            {% for reason, count in stats.override_reasons.items() %}
            <tr>
                <td>{{ reason | replace('_', ' ') | title }}</td>
                <td>{{ count }}</td>
                <td>{% if stats.get('overridden', 0) > 0 %}{{ "%.1f"|format(count / stats.overridden * 100) }}%{% else %}--{% endif %}</td>
                <td>
                    {% if stats.get('total_reviewed', 0) > 0 %}
                    <div class="breakdown-bar-container">
                        <div class="breakdown-bar breakdown-bar--override" style="width: {{ (count / stats.total_reviewed * 100) | round(1) }}%"></div>
                    </div>
                    {% else %}--{% endif %}
                </td>
            </tr>
            {% endfor %}
        </tbody>
    </table>
</div>
{% endif %}

{# Confidence calibration #}
{% if calibration %}
<div class="dashboard-card">
    <h3>Confidence Calibration</h3>
    <p class="calibration-description">
        Shows acceptance rate at each confidence level. Well-calibrated models have higher acceptance
        rates at higher confidence levels.
    </p>
    {% set has_data = calibration | selectattr('total', 'gt', 0) | list | length > 0 %}
    {% if has_data %}
    <table class="data-table">
        <thead>
            <tr>
                <th>Confidence Range</th>
                <th>Total</th>
                <th>Accepted</th>
                <th>Acceptance Rate</th>
                <th>Calibration</th>
            </tr>
        </thead>
        <tbody>
            {% for bucket in calibration %}
            {% if bucket.total > 0 %}
            <tr>
                <td>{{ "%.0f"|format(bucket.bucket_start * 100) }}% &ndash; {{ "%.0f"|format(bucket.bucket_end * 100) }}%</td>
                <td>{{ bucket.total }}</td>
                <td>{{ bucket.accepted }}</td>
                <td>
                    {% if bucket.acceptance_rate is not none %}
                        {{ bucket.acceptance_rate }}%
                    {% else %}
                        --
                    {% endif %}
                </td>
                <td>
                    <div class="calibration-bar-container">
                        <div class="calibration-bar calibration-bar--expected" style="width: {{ ((bucket.bucket_start + bucket.bucket_end) / 2 * 100) | round }}%"
                             title="Expected: {{ "%.0f"|format((bucket.bucket_start + bucket.bucket_end) / 2 * 100) }}%"></div>
                        {% if bucket.acceptance_rate is not none %}
                        <div class="calibration-bar calibration-bar--actual" style="width: {{ bucket.acceptance_rate }}%"
                             title="Actual: {{ bucket.acceptance_rate }}%"></div>
                        {% endif %}
                    </div>
                </td>
            </tr>
            {% endif %}
            {% endfor %}
        </tbody>
    </table>
    <div class="calibration-legend">
        <span class="legend-item"><span class="legend-swatch legend-swatch--expected"></span> Expected (midpoint)</span>
        <span class="legend-item"><span class="legend-swatch legend-swatch--actual"></span> Actual acceptance</span>
    </div>
    {% else %}
    <p class="empty-state">No confidence data available for calibration</p>
    {% endif %}
</div>
{% endif %}

{# Confidence comparison: Accepted vs Overridden #}
{% if stats.get('avg_confidence_accepted') or stats.get('avg_confidence_overridden') %}
<div class="dashboard-card">
    <h3>Confidence: Accepted vs Overridden</h3>
    <div class="confidence-comparison">
        <div class="confidence-group">
            <div class="confidence-label">Accepted Decisions</div>
            <div class="confidence-bar-wrapper">
                {% if stats.get('avg_confidence_accepted') %}
                <div class="confidence-bar confidence-bar--accepted" style="width: {{ (stats.avg_confidence_accepted * 100) | round }}%"></div>
                {% endif %}
            </div>
            <div class="confidence-value">
                {% if stats.get('avg_confidence_accepted') %}
                    {{ "%.1f"|format(stats.avg_confidence_accepted * 100) }}%
                {% else %}
                    --
                {% endif %}
            </div>
        </div>
        <div class="confidence-group">
            <div class="confidence-label">Overridden Decisions</div>
            <div class="confidence-bar-wrapper">
                {% if stats.get('avg_confidence_overridden') %}
                <div class="confidence-bar confidence-bar--overridden" style="width: {{ (stats.avg_confidence_overridden * 100) | round }}%"></div>
                {% endif %}
            </div>
            <div class="confidence-value">
                {% if stats.get('avg_confidence_overridden') %}
                    {{ "%.1f"|format(stats.avg_confidence_overridden * 100) }}%
                {% else %}
                    --
                {% endif %}
            </div>
        </div>
    </div>
</div>
{% endif %}

{# Recent overrides #}
{% if recent_overrides %}
<div class="dashboard-card">
    <h3>Recent Overrides</h3>
    <table class="data-table">
        <thead>
            <tr>
                <th>Module</th>
                <th>Entity</th>
                <th>LLM Recommended</th>
                <th>Human Decision</th>
                <th>Override Reason</th>
                <th>Reviewer</th>
                <th>Reviewed</th>
            </tr>
        </thead>
        <tbody>
            {% for d in recent_overrides %}
            <tr>
                <td>{{ d.module | replace('_', ' ') | title }}</td>
                <td>{{ d.entity_id }}</td>
                <td>{{ d.llm_recommendation }}</td>
                <td>{{ d.human_decision or '--' }}</td>
                <td>{{ d.override_reason | replace('_', ' ') | title if d.override_reason else '--' }}</td>
                <td>{{ d.reviewer_name or '--' }}</td>
                <td>
                    {% if d.reviewed_at %}
                    <span class="relative-time" data-timestamp="{{ d.reviewed_at.isoformat() }}">{{ d.reviewed_at.strftime('%Y-%m-%d %H:%M') }}</span>
                    {% else %}
                    --
                    {% endif %}
                </td>
            </tr>
            {% endfor %}
        </tbody>
    </table>
</div>
{% endif %}

{# Empty state #}
{% if not stats.get('total_reviewed') %}
<div class="dashboard-card">
    <div class="empty-state">
        <h3>No LLM Decision Data Yet</h3>
        <p>LLM extraction decisions will appear here once modules begin logging to the unified LLM tracking system.</p>
    </div>
</div>
{% endif %}

<style>
/* Filter bar */
.llm-filter-bar {
    display: flex;
    align-items: center;
    gap: 1.5rem;
    margin-bottom: 1.5rem;
    padding: 1rem;
    background: #f9fafb;
    border-radius: 8px;
    border: 1px solid #e5e7eb;
}

.llm-filter-group {
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.llm-filter-group label {
    font-size: 0.875rem;
    font-weight: 500;
    color: #374151;
}

.llm-filter-group select {
    padding: 0.375rem 0.75rem;
    border: 1px solid #d1d5db;
    border-radius: 4px;
    font-size: 0.875rem;
    background: white;
}

.page-description {
    color: #6b7280;
    font-size: 0.9rem;
    margin-top: -0.5rem;
    margin-bottom: 1rem;
}

/* Outcome breakdown */
.outcome-summary {
    display: flex;
    gap: 2rem;
    margin: 1rem 0;
}

.outcome-item {
    text-align: center;
    flex: 1;
    padding: 1rem;
    border-radius: 8px;
}

.outcome-accepted {
    background: #f0fdf4;
    border: 1px solid #bbf7d0;
}

.outcome-modified {
    background: #fffbeb;
    border: 1px solid #fde68a;
}

.outcome-overridden {
    background: #fef2f2;
    border: 1px solid #fecaca;
}

.outcome-count {
    display: block;
    font-size: 1.75rem;
    font-weight: bold;
}

.outcome-accepted .outcome-count {
    color: #16a34a;
}

.outcome-modified .outcome-count {
    color: #d97706;
}

.outcome-overridden .outcome-count {
    color: #dc2626;
}

.outcome-label {
    font-size: 0.875rem;
    color: #6b7280;
}

/* Rate badges */
.rate-badge {
    padding: 0.25rem 0.5rem;
    border-radius: 4px;
    font-size: 0.75rem;
    font-weight: bold;
}

.rate-good {
    background: #f0fdf4;
    color: #16a34a;
}

.rate-ok {
    background: #fffbeb;
    color: #d97706;
}

.rate-low {
    background: #fef2f2;
    color: #dc2626;
}

/* Override reason bars */
.breakdown-bar-container {
    height: 20px;
    background: #f3f4f6;
    border-radius: 4px;
    overflow: hidden;
    min-width: 150px;
}

.breakdown-bar {
    height: 100%;
    border-radius: 4px;
}

.breakdown-bar--override {
    background: #ef4444;
}

/* Calibration table */
.calibration-description {
    color: #6b7280;
    font-size: 0.85rem;
    margin-bottom: 1rem;
}

.calibration-bar-container {
    display: flex;
    flex-direction: column;
    gap: 3px;
    width: 200px;
}

.calibration-bar {
    height: 8px;
    border-radius: 4px;
    min-width: 4px;
}

.calibration-bar--expected {
    background: #94a3b8;
    opacity: 0.5;
}

.calibration-bar--actual {
    background: #0d9488;
}

.calibration-legend {
    display: flex;
    gap: 1.5rem;
    margin-top: 1rem;
    font-size: 0.8rem;
    color: #6b7280;
}

.legend-item {
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

.legend-swatch {
    display: inline-block;
    width: 16px;
    height: 8px;
    border-radius: 4px;
}

.legend-swatch--expected {
    background: #94a3b8;
    opacity: 0.5;
}

.legend-swatch--actual {
    background: #0d9488;
}

/* Confidence comparison */
.confidence-comparison {
    display: flex;
    flex-direction: column;
    gap: 1rem;
    padding: 1rem 0;
}

.confidence-group {
    display: flex;
    align-items: center;
    gap: 1rem;
}

.confidence-label {
    width: 160px;
    flex-shrink: 0;
    font-size: 0.875rem;
}

.confidence-bar-wrapper {
    flex: 1;
    height: 24px;
    background: #f3f4f6;
    border-radius: 4px;
    overflow: hidden;
}

.confidence-bar {
    height: 100%;
    border-radius: 4px;
    transition: width 0.5s ease;
}

.confidence-bar--accepted {
    background: linear-gradient(90deg, #0d9488 0%, #14b8a6 100%);
}

.confidence-bar--overridden {
    background: linear-gradient(90deg, #ef4444 0%, #f87171 100%);
}

.confidence-value {
    width: 60px;
    text-align: right;
    font-weight: bold;
    font-size: 0.875rem;
}

/* Stat card modifiers */
.stat-good {
    border-left: 4px solid #16a34a;
}

.stat-warning {
    border-left: 4px solid #f59e0b;
}

.empty-state {
    text-align: center;
    color: #6b7280;
    padding: 2rem;
}

.empty-state h3 {
    margin-bottom: 0.5rem;
}
</style>
{% endblock %}
